# book-rec-engine

## Why?
Two things about me: I love books and I love reading. As such, I am always revisiting the question of "What to read next?" as my tastes evolve and my interests bounce from one subject to another. I use tools like Goodreads as much as I use actual social media sites. But as most people know, Goodreads sucks. This is for a myriad of reasons, but most importantly to this project, their recommendation system is lousyyyyyy. Their are so many advancements in the field of ML and NLP that have improved the efficacy of recommendation systems across the media spectrum. My goal is to use one of these techniques to implement a new and more robust algorithm for recommending new books to read. 

## How?
This program leverages the UCSD Book Graph Goodreads dataset to represent a vast array of novels acorss all genres, centuries, and authors. This information is aggregated and stored in a vector space via embedding generation. This allows us to more adeptly examine and identify the similarities between books in regards to style, semantics, and feeling, providing recommendations far less surface level than other available recommendation services currently available.

### data_generation.py
The first file that works to fulfill the mission of this project has a few key steps. Firstly the program downloads the necessary files using the urllib python package from the UCSD Goodreads Bookgraph dataset. These are downloaded into the newly created data folder to keep them separated from the rest of the repo. Next, the data is loaded and filtered, throwing out books with fewer than 100 reviews or incomplete data, and retreiving only necessary data from the remaining books, leaving ~300,000 entries in the dataset. From there, that data is combined with the author and fuzzy genre data, replacing the numeric author id currently stored in the objects with actual author names, as well as some general book tags. Finally, context strings based on each book's data is generated and saved to the user's computer. 

### book_embedding.py
The next step in our project is generating the vector embeddings at the heart of our recommendation engine. The data we generated from the previous file is loaded(necessary?) and passed to our SentenceTransformer model to generate the embeddings. From there, we generate a dictionary with two key-value pairs, one key is the title of the book allowing us to look it up later, and the other key is the corresponding vector generated by the model based off our context strings. This list of dictionaries is then saved to a gzipped jsonl file to be used later on.

### rec_engine.py
Rec_engine.py is the primary user facing python file in our package. Our title, vector pairs are
loaded to start, and from this data a FAISS index is generated. The user is then queried for
relevant recommendation information, then the main loop starts. A search is performed on the index with a user inputted query title, and the index returns the scores and indicies from the
index search. The results are then compiled in a user readable format and printed to the console.
Finally, the user can either enter another book or type "quit" to quit.